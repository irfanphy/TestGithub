{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projects for day 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General structure for all projects\n",
    "\n",
    "Below, we give you some ideas for more advanced projects python. In all these cases we would like you to do all of the following tasks:\n",
    "\n",
    "#### Basic tasks\n",
    "\n",
    "- Discuss beforehand the structure of the code that you want to write.\n",
    "- Use git to keep track of your collaborative project, and upload it to github to share with your partner.\n",
    "- structure your code into modules (i.e. have functions etc. in files separate from your notebooks that use it).\n",
    "- Add tests checking your code.\n",
    "- Work independently on different parts of the code (i.e. on different functions, or test/function).\n",
    "- Introduce an error in your code that does is not captured by the test, and let your partner debug the code to find the error. Improve the test to also cover this error.\n",
    "\n",
    "#### Additional tasks\n",
    "\n",
    "- Make your code a package that you can install globally on your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract information from text\n",
    "\n",
    "Make a module to extract information from some text stored in a string. Possible functionality could be:\n",
    "\n",
    "- count number of words/letters in a text.\n",
    "- count how many times a word accurs in a text.\n",
    "- find all occurences of a word in a text, and output the word together with it's surrounding. For example, output 5 words before or after, or the whole sentence.\n",
    "- Be creative!\n",
    "- The text can be also provided through a filename, or a URL. Adapt your code to accept different sources of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak finder\n",
    "\n",
    "Make a module for searching and fitting for resonant peaks in noisy data.\n",
    "\n",
    "- Your procedure needs to be resistant against noise, think how you are going to find the peaks.\n",
    "- Implement generating mock signal so that you can test your procedure systematically.\n",
    "- How would you estimate the error in the fit results?\n",
    "- Does your procedure work if the points are not measured homogeneously?\n",
    "- What about finding several peaks (an amount not known in advance)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latex converter\n",
    "\n",
    "Implement a script that tracks all the latex files in one folder and compiles them into pdf files in another folder. It should run persistently, so that when a new file is added, modified, or an old one is removed, the pdfs are automatically updated. You will need to install latex for this: run `sudo apt-get install texlive` in terminal. In terminal compiling a latex file into pdf is done by just running `pdflatex mydocument.tex`.\n",
    "\n",
    "In this project you'll need to call terminal programs from Python. Watching for updates in a folder can be done in many ways, but the easiest is probably just to check for changes every couple of seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image compression\n",
    "\n",
    "(Useful project if you are already familiar with what a 'SVD' is.)\n",
    "\n",
    "Images can easily be represented as numpy arrays in python (for example, using ``matplotlib.image.imread`` for loading PNG files). A simple to implement compression scheme for this data is based on the singular value decomposition (SVD): A $N\\times N$-matrix $A$ can be decomposed as $A = U S V^\\dagger$ where $U$ and $V$ are $N\\times N$ unitary matrices, and $S$ is a $N\\times N$ diagonal matrix with positive entries $s_i$ on the diagonal.\n",
    "\n",
    "If we take only the largest $M\\ll N$ entries $s_i$, and set the remaining $s_i$ to zero, we get an approximation for $A$: $A \\approx \\tilde{U} \\tilde{S} \\tilde{V}^\\dagger$, where\n",
    "$\\tilde{U}$ and $\\tilde{V}$ are now $N\\times M$ matrices (the first $M$ columns of $U$ and $V$), and $\\tilde{S}$ a $M\\times M$ matrix with the largest $s_i$ on the diagonal. But if $M \\ll N$, we now need much less information to approximately store the image, and hence we compressed it.\n",
    "\n",
    "Write a module for compressing images, writing compressed images to a file, reading it again and displaying the image on the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse arXiv data\n",
    "\n",
    "\n",
    "Make use of arXiv [api](http://arxiv.org/help/api/index#python_simple_example) to do simple visualisations:\n",
    "\n",
    "1. count how many publications with word **novel** in title (abstract) appears each day (month, or even year) and plot it. Compare with a word **revisit**. How often do these two appear together?\n",
    "2. make histogram of lengths (amount of words) of abstracts from every paper where your supervisor is one of authors\n",
    "\n",
    "Advice:\n",
    "* search for information about ``feedparser.parse``, it may be useful\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
